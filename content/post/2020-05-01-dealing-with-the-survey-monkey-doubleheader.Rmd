---
title: Tidying The Survey Monkey Doubleheader
author: Matt Roumaya
date: '2020-05-02'
slug: dealing-with-the-survey-monkey-doubleheader
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-05-02T16:38:05-04:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

![](/post/2020-05-01-dealing-with-the-survey-monkey-doubleheader_files/sm.png){width=400px height=200px}

SurveyMonkey `r emo::ji("monkey")` is a popular online survey development software that outputs a very frustrating kind of response file.  If you've ever received exported results from SurveyMonkey, you probably know what I'm talking about. 

When response data is exported as a *.csv* or *.xlsx* file, it looks something like this: 

![The Doubleheader](/post/2020-05-01-dealing-with-the-survey-monkey-doubleheader_files/doubleheader.png)

You can see that the response data for the question *"Please provide your contact information:"* contains several inputs for Name, Company, Address, etc. Deleting the first row might seem to make sense at first, but when your survey contains dozens of questions with multiple question types, things can get out of hand really fast.

This post is an overview of one approach for cleaning up SurveyMonkey columns. I struggled with this for a while, but now have a workflow that seems pretty efficient, especially if your goal is to set up `RMarkdown` reports while your survey is being administered. If it is helpful for you, that's awesome! If you have a better way of approaching this issue, please let me know! 


# The workflow
1. A function that creates column names that are concatenated from the question + response in_snake_case (or camelCase, or whatever) using the aptly-named `janitor` package.  
2. Cleaning up any annoying/extremely_long_column_names_from_very_long_questions.  
3. If needed, subsetting columns into dataframes or lists for analyses/visualization. (The `dplyr` functions `starts_with` and `ends_with` work really well with this workflow).  
4. That's it, now you're ready to do some meaningful analyses!  

**Let's start by viewing our response data. You'll need to use the packages `tidyverse`, `janitor`, and `readxl` if you're using *.xlsx*.** 

(I always save the original version without any changes so I can build in QC checks, and tend to use `_preserve` as an identifier.) You'll see that some columns are missing values, and will be read in with **"...#"**

```{r include=FALSE}
library(tidyverse)
library(readxl)
library(janitor)
```

```{r}

path <- "C:/Users/MR/Desktop/Dummy Data Survey.xlsx"

# Keep this file for QC
survey_data_preserve <- as_tibble(read_excel(path))

survey_data <- survey_data_preserve

```

```{r include=FALSE}
library(kableExtra)
survey_data <- survey_data[-c(2,3),]
```

```{r read in data, echo=TRUE}

kable(head(survey_data[,10:15]))

```

# Ugh! Look at those terrible column names. `r emo::ji("annoyed")`

![Oof!!!](/post/2020-05-01-dealing-with-the-survey-monkey-doubleheader_files/IMG-2932.JPG)

It's okay, we've got a function for that!
[(thanks to akrun on SO)](https://stackoverflow.com/questions/60456987/renaming-columns-by-pasting-first-row-if-not-na/)

# The big reveal!

Here's the function in its entirety, where you only need to supply a value for `x`, which should be your SurveyMonkey dataframe. Below, I'll go through the function line-by-line (for the most part), and at the end, show how I would clean up this data file.

P.S. If **snake_case** isn't your thing, there are a [bunch of different cases](http://127.0.0.1:26376/library/snakecase/html/to_any_case.html) you can pass to `clean_names(case = X)` at the end of the function.   

```{r sm func, echo = TRUE}

double_header <- function(x) {
  
  df <- as_tibble(x)
  
  keydat <- df %>%
    slice(1) %>%
    select_if(negate(is.na)) %>%
    pivot_longer(everything()) %>%
    group_by(grp = cumsum(!startsWith(name, "..."))) %>%
    mutate(value = sprintf("%s (%s)", first(name), value)) %>%
    ungroup %>%
    select(-grp)
  
  df <- df %>%
    rename_at(vars(keydat$name), ~ keydat$value) %>%
    slice(-1) %>%
    clean_names()
}

```

# The double header breakdown 
1. `slice(1)` selects the first row, which contains the other names we need.    
2. `select_if(negate(is.na))` selects all columns where the first row is not `NA`, because we don't need to alter these column names.    
3. `pivot_longer(everything())` transforms our dataframe from wide to long, and automatically creates the columns `name` and `value`.  
  * (`name` holds all of our column names and `value` holds all of our secondary column names.)  

```{r pivot longer example, echo=FALSE}

keydat <- survey_data %>%
  slice(1) %>%
  select_if(negate(is.na)) %>%
  pivot_longer(everything())


#Step 3: pivot_longer(everything())
print(head(keydat))

```

4. `group_by(grp = cumsum(!startsWith(name, "...")))` groups rows and then applies a cumulative sum for all rows in the `name` column that do not start with **"..."** until a row other than **"..."** is encountered. This is better shown in the table below:  

```{r group_by example 2, echo = FALSE}

keydat <- survey_data %>%
  slice(1) %>%
  select_if(negate(is.na)) %>%
  pivot_longer(everything()) %>%
  group_by(grp = cumsum(!startsWith(name, "...")))

kable(keydat)

```

5. `mutate(value = sprintf("%s (%s)", first(name), value))` updates our `value` column and concatenates our names so that they're meaningful. We're almost there!

```{r mutate example, echo = FALSE}

keydat <- survey_data %>%
  slice(1) %>%
  select_if(negate(is.na)) %>%
  pivot_longer(everything()) %>%
  group_by(grp = cumsum(!startsWith(name, "..."))) %>%
  mutate(value = sprintf("%s (%s)", first(name), value))

kable(head(keydat))

```

6. Then we just `ungroup` and drop the `grp` column.  
7. Finally, we rename the columns in our `survey_data` by using our updated names in `keydat$value`, and call `clean_names()` to convert to snake_case `r emo::ji("snake")`

# All together now

Let's run the function on `survey_data`
```{r all together header}

survey_data <- double_header(survey_data)

```

**Here's a comparison of our original names and our cleaned names:**
```{r all together now,echo = FALSE}


preserve_names <- as.data.frame(colnames(survey_data_preserve))
new_names <- as.data.frame(colnames(survey_data))
combine <- as.data.frame(cbind(preserve_names, new_names))%>%
  rename("Old Names" = "colnames(survey_data_preserve)",
         "New Names" = "colnames(survey_data)")

kable(combine)

```

# Subsetting made easy! 

Now if we want to subset data based on certain questions/columns, we can do it really easily using `starts_with` and `ends_with`. 

Sometimes it's easier to rename columns so that they're shorter and easier to work with, and sometimes it's fine to keep some really long column names if your survey contains a lot of similar questions.

Below, we'll combine all of the questions that start with `please_provide_your_contact_information` and shorten the names to only start with `contact_information` + `value`.

**`starts_with` example:**
```{r starts_with subset}

contact_info <- survey_data %>%
  select(starts_with("please_provide_your_contact_information")) %>%
  rename_at(vars(starts_with("please")), ~str_remove(.,"please_provide_your_"))

kable(head(contact_info))

```

`ends_with` is really helpful in combination with our `double_header` function and SurveyMonkey data, because open-ended or free-text responses all end with *...open_ended_response*

Depending on the report or project you're building, it's sometimes useful to add all of your free-text responses as dataframes in a list, to include as an appendix, or to select important comments to include in an executive summary.

**`ends_with` example:**
```{r ends_with subset}

open_ended <- survey_data %>%
  select(ends_with("open_ended_response")) %>%
  map(., function(x) as.data.frame(x))

print(names(open_ended))

```

That's it for this post! I'd love to hear from you if you found this workflow helpful, or if there is any way it could be improved. 

Some ideas for future posts include building this function into a package (for the sole purpose of learning how to build `R` packages), showing a few tricks I've learned with the `HH` and `lattice` packages for visualizing Likert scale responses, and some more trivial posts about Rummy, House Hunters, and any other reality TV my wife and I are currently fixated on. 


